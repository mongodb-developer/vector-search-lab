{"searchDocs":[{"title":"üëê Create a Vector Search Index","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/building-vector-search/create-a-vector-search-index","content":"üëê Create a Vector Search Index You can create vector search indexes using the Atlas web UI, Atlas CLI, Compass, or any MongoDB driver. We'll create a vector search index using the Python driver. CODE_BLOCK_7 Answer collection.create_search_index(model=model) ","keywords":"","version":"Next"},{"title":"üìòüëê Similarity Functions","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/advanced-features/similarity-functions","content":"üìòüëê Similarity Functions Atlas Vector Search supports different similarity functions to search for top K-nearest neighbors. You can set the similarity function for vector type fields in your index definition. euclidean - measures the distance between ends of vectors.cosine - measures similarity based on the angle between vectors.dotProduct - measures similarity like cosine, but takes into account the magnitude of the vector. üìö About the similarity functions CODE_BLOCK_15 Answer { &quot;name&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;type&quot;: &quot;vectorSearch&quot;, &quot;definition&quot;: { &quot;fields&quot;: [ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 512, &quot;similarity&quot;: &quot;dotProduct&quot;, }, ] }, } ","keywords":"","version":"Next"},{"title":"üëê Run Vector Queries","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/building-vector-search/run-vector-queries","content":"üëê Run Vector Queries Let's perform vector queries against our vector search index. First, we'll vectorize the user's query (text or image) using the same CLIP model we used for the book covers. Then we'll use these query vectors to search for semantically similar book covers in our vector search index. CODE_BLOCK_8 Answer get_embedding(user_query, mode) CODE_BLOCK_9 Answer [ { &quot;$vectorSearch&quot;: { &quot;index&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;queryVector&quot;: query_embedding, &quot;path&quot;: &quot;embedding&quot;, &quot;numCandidates&quot;: 50, &quot;filter&quot;: filter, &quot;limit&quot;: 5, } }, {&quot;$project&quot;: {&quot;_id&quot;: 0, &quot;title&quot;: 1, &quot;score&quot;: {&quot;$meta&quot;: &quot;vectorSearchScore&quot;}}}, ] CODE_BLOCK_10 Answer collection.aggregate(pipeline) ","keywords":"","version":"Next"},{"title":"üìòüëê Vector Quantization","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/advanced-features/vector-quantization","content":"üìòüëê Vector Quantization Vector Quantization is a technique to reduce the number of bits that represent a vector. This can help reduce the storage and memory requirements for vector embeddings. Atlas Vector Search supports automatic quantization of double or 32-bit float values in your vector embeddings. You can set the quantization method for vector type fields in your index definition. üìö Vector Quantization CODE_BLOCK_16 Answer { &quot;name&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;type&quot;: &quot;vectorSearch&quot;, &quot;definition&quot;: { &quot;fields&quot;: [ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 512, &quot;similarity&quot;: &quot;cosine&quot;, &quot;quantization&quot;: &quot;scalar&quot;, }, ] }, } ","keywords":"","version":"Next"},{"title":"üìòüëê Pre-Filtering","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/advanced-features/pre-filtering","content":"","keywords":"","version":"Next"},{"title":"Published after the year 2000‚Äã","type":1,"pageTitle":"üìòüëê Pre-Filtering","url":"/vector-search-lab/docs/advanced-features/pre-filtering#published-after-the-year-2000","content":" CODE_BLOCK_11  Answer { &quot;name&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;type&quot;: &quot;vectorSearch&quot;, &quot;definition&quot;: { &quot;fields&quot;: [ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 512, &quot;similarity&quot;: &quot;cosine&quot;, }, {&quot;type&quot;: &quot;filter&quot;, &quot;path&quot;: &quot;year&quot;}, ] }, }   CODE_BLOCK_12  Answer {&quot;year&quot;: {&quot;$gte&quot;: 2000}}   ","version":"Next","tagName":"h3"},{"title":"Published after the year 2000 and under 100 pages‚Äã","type":1,"pageTitle":"üìòüëê Pre-Filtering","url":"/vector-search-lab/docs/advanced-features/pre-filtering#published-after-the-year-2000-and-under-100-pages","content":" CODE_BLOCK_13  Answer { &quot;name&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;type&quot;: &quot;vectorSearch&quot;, &quot;definition&quot;: { &quot;fields&quot;: [ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 512, &quot;similarity&quot;: &quot;cosine&quot;, }, {&quot;type&quot;: &quot;filter&quot;, &quot;path&quot;: &quot;year&quot;}, {&quot;type&quot;: &quot;filter&quot;, &quot;path&quot;: &quot;pages&quot;}, ] }, }   CODE_BLOCK_14  Answer {&quot;$and&quot;: [{&quot;year&quot;: {&quot;$gte&quot;: 2000}}, {&quot;pages&quot;: {&quot;$lte&quot;: 100}}]}  ","version":"Next","tagName":"h3"},{"title":"üëê Store Embeddings","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/building-vector-search/store-embeddings","content":"","keywords":"","version":"Next"},{"title":"Generate Embeddings for book cover images‚Äã","type":1,"pageTitle":"üëê Store Embeddings","url":"/vector-search-lab/docs/building-vector-search/store-embeddings#generate-embeddings-for-book-cover-images","content":" First, you'll need to choose an appropriate embedding model. For this use case, we'll use CLIP, a multimodal model that can handle both images and text. CLIP generates 512-dimensional vectors that capture the semantic meaning of both images and text in the same vector space.  CODE_BLOCK_2  Answer embedding_model.encode(image).tolist()   ","version":"Next","tagName":"h3"},{"title":"Store them along with your book documents‚Äã","type":1,"pageTitle":"üëê Store Embeddings","url":"/vector-search-lab/docs/building-vector-search/store-embeddings#store-them-along-with-your-book-documents","content":" After generating embeddings for your book cover images, store them in MongoDB Atlas along with your book documents. These embeddings can then be used to create a vector search index for your bookstore.  CODE_BLOCK_3  Answer collection.find({})   CODE_BLOCK_4  Answer get_embedding(content, &quot;image&quot;)   CODE_BLOCK_5  Answer {&quot;$set&quot;: {embedding_field: embedding}}   CODE_BLOCK_6  Answer collection.update_one(filter, update)  ","version":"Next","tagName":"h3"},{"title":"üëê Setup dev environment","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/getting-started/dev-env-setup","content":"","keywords":"","version":"Next"},{"title":"Option 1: GitHub Codespaces‚Äã","type":1,"pageTitle":"üëê Setup dev environment","url":"/vector-search-lab/docs/getting-started/dev-env-setup#option-1-github-codespaces","content":" You will be working in a Jupyter Notebook in a GitHub Codespace throughout this lab. A codespace is a cloud-hosted, containerized development environment that comes pre-configured with all the tools you need to run this lab.  Navigate to this link. You will be prompted to sign into GitHub if you haven't already. Once signed in, click the Create new codespace button to create a new codespace.    Let it run for a few seconds as it prepares your environment. It will clone the repository, prepare the container, and run the installation scripts. Once the environment is built, you should see a list of files appear under the Explorer.  In the left navigation bar of the IDE, click on the file named ai-rag-lab.ipynb to open the Jupyter Notebook for this lab.    Next, select the Python interpreter by clicking Select Kernel at the top right of the IDE.    In the modal that appears, click Python environments... and select the interpreter that is marked as Recommended or Global Env.      That's it! You're ready for the lab!  ","version":"Next","tagName":"h2"},{"title":"Option 2: Run locally‚Äã","type":1,"pageTitle":"üëê Setup dev environment","url":"/vector-search-lab/docs/getting-started/dev-env-setup#option-2-run-locally","content":" caution During the lab, we will use GitHub Codespaces. These instructions are here just in case you can't use Codespaces or if you really, really, really want a local installation.  If you want to run the notebook locally, follow the steps below:  Clone the GitHub repo for this lab by executing the following command from the terminal:  git clone https://github.com/mongodb-developer/genai-devday-notebooks.git   cd into the cloned directory:  cd genai-devday-notebooks   Create and activate a Python virtual environment:  python -m venv mongodb-ai-rag-lab source mongodb-ai-rag-lab/bin/activate   Install the dependencies for this lab:  pip install -r requirements.txt   Install and launch Jupyter Notebook:  pip install notebook jupyter notebook   In the browser tab that pops up, open the file named ai-rag-lab.ipynb.   ","version":"Next","tagName":"h2"},{"title":"üëê MongoDB Atlas setup","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/getting-started/mongodb-setup","content":"üëê MongoDB Atlas setup In this lab, you will learn how to use MongoDB Atlas as a knowledge base as well as a memory provider for a RAG-based documentation chatbot. To use MongoDB Atlas, you will need to create an account, a free cluster and obtain the connection string to connect to your cluster. Follow these steps to get set up: Register for a free MongoDB Atlas account Create a new database cluster Obtain the connection string for your database cluster","keywords":"","version":"Next"},{"title":"üëê Import data into MongoDB","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/getting-started/import-data","content":"üëê Import data into MongoDB Let's first import a dataset to use for this lab. Run the cells under the Step 2: Import data section in the notebook to import the dataset for this lab . To verify that the data has been imported into your MongoDB cluster, navigate to the Overview page in the Atlas UI. In the Clusters section, select your cluster and click Browse collections. Ensure that you see a database called mongodb_genai_devday, and a collection named books under it. Note the number and format of documents in the collection.","keywords":"","version":"Next"},{"title":"Introduction","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/intro","content":"","keywords":"","version":"Next"},{"title":"Lab goals‚Äã","type":1,"pageTitle":"Introduction","url":"/vector-search-lab/docs/intro#lab-goals","content":" Learn how to build vector search on MongoDB Atlas  ","version":"Next","tagName":"h3"},{"title":"What you'll learn‚Äã","type":1,"pageTitle":"Introduction","url":"/vector-search-lab/docs/intro#what-youll-learn","content":" What is vector searchWhat are embeddingsHow to store embeddings along with MongoDB documentsHow to create a vector search indexHow to run vector queriesHow to optimize vector searchDifferent search methods in MongoDB and hybrid approaches  ","version":"Next","tagName":"h3"},{"title":"Time to complete‚Äã","type":1,"pageTitle":"Introduction","url":"/vector-search-lab/docs/intro#time-to-complete","content":" 120 mins  ","version":"Next","tagName":"h3"},{"title":"Navigation bar icons‚Äã","type":1,"pageTitle":"Introduction","url":"/vector-search-lab/docs/intro#navigation-bar-icons","content":" In the navigation bar and in some pages, you will notice some icons. Here is their meaning:  Icon\tMeaning\tDescriptionüìò\tLecture material\tIf you are following along in an instructor-led session, they probably have covered this already. üëê\tHands-on content\tGet ready to do some hands-on work. You should follow these steps. üìö\tDocumentation\tReference documentation for hands-on portions of the lab. ü¶π\tAdvanced content\tThis content isn't covered during the lab, but if you're interested in learning more, you can check it out. ","version":"Next","tagName":"h3"},{"title":"üìò Running Jupyter Notebooks","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/getting-started/jupyter-notebooks","content":"","keywords":"","version":"Next"},{"title":"Cells‚Äã","type":1,"pageTitle":"üìò Running Jupyter Notebooks","url":"/vector-search-lab/docs/getting-started/jupyter-notebooks#cells","content":" Cells in a Jupyter notebook are a modular unit of code or text that you can execute and view outputs for.  ","version":"Next","tagName":"h2"},{"title":"Running a cell‚Äã","type":1,"pageTitle":"üìò Running Jupyter Notebooks","url":"/vector-search-lab/docs/getting-started/jupyter-notebooks#running-a-cell","content":" To run a cell in a Jupyter notebook, hover over it and click the Run icon that appears against the cell.    When a cell is running, you will see a loading spinner in the bottom left corner of the cell.    ","version":"Next","tagName":"h2"},{"title":"Successful cell runs‚Äã","type":1,"pageTitle":"üìò Running Jupyter Notebooks","url":"/vector-search-lab/docs/getting-started/jupyter-notebooks#successful-cell-runs","content":" When a cell is finished running successfully, you will see a green check mark appear in the bottom left corner of the cell.    ","version":"Next","tagName":"h2"},{"title":"Erroneous cell runs‚Äã","type":1,"pageTitle":"üìò Running Jupyter Notebooks","url":"/vector-search-lab/docs/getting-started/jupyter-notebooks#erroneous-cell-runs","content":" If an error occurred while running a cell, you will see a red cross appear in the bottom left corner of the cell, and also an error traceback after the cell.    To fix errors, you may need to update previous cells. If you do, re-run all the cells following the one(s) you updated.  ","version":"Next","tagName":"h2"},{"title":"Interrupting a cell‚Äã","type":1,"pageTitle":"üìò Running Jupyter Notebooks","url":"/vector-search-lab/docs/getting-started/jupyter-notebooks#interrupting-a-cell","content":" To interrupt a running cell, click the Stop icon that you see against the cell while it is running.    warning The UI might differ slightly if you are running Jupyter Notebooks in a different IDE. Refer to the appropriate documentation if running the notebook in a different environment. ","version":"Next","tagName":"h2"},{"title":"üìò Embeddings","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/key-concepts/embeddings","content":"","keywords":"","version":"Next"},{"title":"Vector‚Äã","type":1,"pageTitle":"üìò Embeddings","url":"/vector-search-lab/docs/key-concepts/embeddings#vector","content":" A vector is an array of numbers that represent magnitude and direction in a multi-dimensional space.  ","version":"Next","tagName":"h2"},{"title":"Embeddings‚Äã","type":1,"pageTitle":"üìò Embeddings","url":"/vector-search-lab/docs/key-concepts/embeddings#embeddings","content":" Embeddings are vectors that represent a piece of information, such as text, images, audio, video etc. Embeddings capture semantic qualities of the data i.e. characteristics that capture the meaning or essence of it.  This way, if you plot data in this multi-dimensional vector space, semantically similar data, or data with similar meaning ends up close to each other.  ","version":"Next","tagName":"h2"},{"title":"Embedding models‚Äã","type":1,"pageTitle":"üìò Embeddings","url":"/vector-search-lab/docs/key-concepts/embeddings#embedding-models","content":" Embedding models are specialized machine learning models that have been trained to convert a piece of information to these numerical encodings.  The embedding model you choose determines the number of elements in the embedding vectors, and consequently the number of dimensions required to represent them in vector space.  Embedding models vary depending on how the model was trained. Therefore, different models offer different advantages depending on your data and use case. While text embedding models are widely used, embedding models also exist for other types of data such as images, audio, and multimodal content. ","version":"Next","tagName":"h2"},{"title":"üìò Atlas Search","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/other-search-methods/atlas-search","content":"","keywords":"","version":"Next"},{"title":"Usage Example‚Äã","type":1,"pageTitle":"üìò Atlas Search","url":"/vector-search-lab/docs/other-search-methods/atlas-search#usage-example","content":" { &quot;$search&quot;: { &quot;index&quot;: &quot;default&quot;, &quot;text&quot;: { &quot;query&quot;: &quot;search term&quot;, &quot;path&quot;: &quot;fieldName&quot; } } }  ","version":"Next","tagName":"h3"},{"title":"üìò .find()","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/other-search-methods/find","content":"","keywords":"","version":"Next"},{"title":"Usage Example‚Äã","type":1,"pageTitle":"üìò .find()","url":"/vector-search-lab/docs/other-search-methods/find#usage-example","content":" db.collection.find({ &quot;name&quot;: &quot;Alice&quot; })  ","version":"Next","tagName":"h3"},{"title":"üìò Vector Search","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/key-concepts/vector-search","content":"","keywords":"","version":"Next"},{"title":"Vector search‚Äã","type":1,"pageTitle":"üìò Vector Search","url":"/vector-search-lab/docs/key-concepts/vector-search#vector-search","content":" Vector search, a.k.a. semantic search is an information retrieval technique that retrieves data based on intent or meaning.  Unlike traditional full-text search which finds keyword matches, vector search uses embeddings to find items closest to your search query in multi-dimensional vector space. The closer the embeddings are to your query, the more similar they are in meaning.  ","version":"Next","tagName":"h2"},{"title":"Vector search in MongoDB‚Äã","type":1,"pageTitle":"üìò Vector Search","url":"/vector-search-lab/docs/key-concepts/vector-search#vector-search-in-mongodb","content":" In MongoDB, you can semantically search through your data using MongoDB Atlas Vector Search.  To perform vector search on your data in MongoDB, you need to create a vector search index. An example of a vector search index definition looks as follows:  { &quot;fields&quot;:[ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 1536, &quot;similarity&quot;: &quot;cosine&quot; }, { &quot;type&quot;: &quot;filter&quot;, &quot;path&quot;: &quot;pages&quot; }, ... ] }   In the index definition, you specify the path to the embedding field (path), the number of dimensions in the embedding vectors (numDimensions), and a similarity metric that specifies how to determine nearest neighbors in vector space (similarity). You can also index filter fields that allow you to pre-filter on certain metadata to narrow the scope of the vector search.  Vector search in MongoDB takes the form of an aggregation pipeline stage. It always needs to be the first stage in the pipeline and can be followed by other stages to further process the semantic search results. An example pipeline including the $vectorSearch stage is as follows:  [ { &quot;$vectorSearch&quot;: { &quot;index&quot;: &quot;vector_index&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;queryVector&quot;: [0.02421053, -0.022372592,...], &quot;numCandidates&quot;: 150, &quot;filter&quot;: {&quot;pages&quot;: 100}, &quot;limit&quot;: 10 } }, { &quot;$project&quot;: { &quot;_id&quot;: 0, &quot;title&quot;: 1, &quot;score&quot;: {&quot;$meta&quot;: &quot;vectorSearchScore&quot;} } } ]   In this example, you can see a vector search query with a pre-filter. The limit field in the query definition specifies how many documents to return from the vector search.  The $project stage that follows only returns documents with the title field and the similarity score from the vector search. ","version":"Next","tagName":"h2"},{"title":"Summary","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/summary","content":"Summary Congratulations! Following this workshop, you have successfully learned: ‚úÖ What is vector search‚úÖ What are embeddings‚úÖ How to store embeddings along with MongoDB documents‚úÖ How to create a vector search index‚úÖ How to run vector queries‚úÖ How to optimize vector search‚úÖ Different search methods in MongoDB and hybrid approaches Visit the links for more resources on vector search and other MongoDB features: Atlas Vector Search OverviewAtlas Vector Search DocumentationMongoDB Developer Center","keywords":"","version":"Next"},{"title":"ü¶π‚Äç‚ôÄÔ∏è Hybrid Search","type":0,"sectionRef":"#","url":"/vector-search-lab/docs/other-search-methods/hybrid-search","content":"ü¶π‚Äç‚ôÄÔ∏è Hybrid Search üìö How to Perform Hybrid Search Hybrid search in MongoDB combines Atlas Vector Search and Atlas Search to provide unified search results. This approach leverages the strengths of both full-text search and semantic search to deliver more relevant results. CODE_BLOCK_17 Answer { &quot;name&quot;: ATLAS_VECTOR_SEARCH_INDEX_NAME, &quot;type&quot;: &quot;vectorSearch&quot;, &quot;definition&quot;: { &quot;fields&quot;: [ { &quot;type&quot;: &quot;vector&quot;, &quot;path&quot;: &quot;embedding&quot;, &quot;numDimensions&quot;: 512, &quot;similarity&quot;: &quot;cosine&quot;, &quot;quantization&quot;: &quot;scalar&quot;, }, ] }, } ","keywords":"","version":"Next"}],"options":{"id":"default"}}